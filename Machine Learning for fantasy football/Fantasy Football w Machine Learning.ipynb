{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting performance direction of Premier League Footballers using 'Fantasy Football' data and Machine learning\n",
    "\n",
    "Using a LTSM neural network trained with data collected from 3 seasons of Premier League Football games, a predictive model of player performance was made. By 'direction of performance,' it is simply meant whether a player performed better or worse in the next matched player relative to the previous week, i.e. a simple binary choice. Thus, a categorical model is used here.\n",
    "\n",
    "Below the construction of this model is outlined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing and normalizing data\n",
    "The data being used to train the model has been collected from the Official Premier League online game 'Fantasy Premier League.\" This online game tracks multiple performance attributes for the sport, such as number of shots or number of fouls committed by each player every week, and based on these variables gives each player a score every week. The score that each player gets depends primarily on the number of bonus points ('bps') they recieve, which is determined by set rules- for example 4 bps if they score a goal, 2 bps for playing 90 minutes (the length of a premier league football match) or -2 points if the player receives a red card. These rules are not of direct consequence for the analysis but the full list is found here- https://fantasy.premierleague.com/help/rules.\n",
    "\n",
    "The number of bps awarded to a given player additionally depends on how well that player performs relative to other players in the same match for that week. Thus, bps, and total points awarded per week, are sufficiently random variables that prediction of them is a problem well suited for machine learning, given the large number of variables which may impact these dependent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step for the analysis is to import the data, which is seperated into data for each season, and within each season separated into individual .csv files for each player. Each file then has various attribute values recorded for each week (of which there are 38 weeks). We begin by importing the required modules and defining the classification function, which will be used for defining the performance direction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "def classify(current, future):\n",
    "    if float(future) > float(current):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the csv files need to be processed. Using the file 'raw_data/2016-17/players/Sergio_Agüero/gw.csv' as an example to show the format of these files, we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['assists', 'attempted_passes', 'big_chances_created',\n",
       "       'big_chances_missed', 'bonus', 'bps', 'clean_sheets',\n",
       "       'clearances_blocks_interceptions', 'completed_passes', 'creativity',\n",
       "       'dribbles', 'ea_index', 'element', 'errors_leading_to_goal',\n",
       "       'errors_leading_to_goal_attempt', 'fixture', 'fouls', 'goals_conceded',\n",
       "       'goals_scored', 'ict_index', 'id', 'influence', 'key_passes',\n",
       "       'kickoff_time', 'kickoff_time_formatted', 'loaned_in', 'loaned_out',\n",
       "       'minutes', 'offside', 'open_play_crosses', 'opponent_team', 'own_goals',\n",
       "       'penalties_conceded', 'penalties_missed', 'penalties_saved',\n",
       "       'recoveries', 'red_cards', 'round', 'saves', 'selected', 'tackled',\n",
       "       'tackles', 'target_missed', 'team_a_score', 'team_h_score', 'threat',\n",
       "       'total_points', 'transfers_balance', 'transfers_in', 'transfers_out',\n",
       "       'value', 'was_home', 'winning_goals', 'yellow_cards'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = pd.read_csv(\"raw_data/2016-17/players/Sergio_Agüero/gw.csv\")\n",
    "dat.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine which variables potentially correlate with 'bps' and 'total_points,' the variable which the model will predict, use the corr() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bps</th>\n",
       "      <th>future_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>assists</th>\n",
       "      <td>0.500451</td>\n",
       "      <td>-0.194994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attempted_passes</th>\n",
       "      <td>0.586816</td>\n",
       "      <td>0.170655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>big_chances_created</th>\n",
       "      <td>0.333012</td>\n",
       "      <td>-0.004426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>big_chances_missed</th>\n",
       "      <td>0.048586</td>\n",
       "      <td>0.197941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bonus</th>\n",
       "      <td>0.909670</td>\n",
       "      <td>-0.015912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bps</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.013018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clean_sheets</th>\n",
       "      <td>0.282780</td>\n",
       "      <td>0.242436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clearances_blocks_interceptions</th>\n",
       "      <td>0.188060</td>\n",
       "      <td>0.089263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>completed_passes</th>\n",
       "      <td>0.614451</td>\n",
       "      <td>0.130888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creativity</th>\n",
       "      <td>0.728404</td>\n",
       "      <td>0.156208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dribbles</th>\n",
       "      <td>0.241634</td>\n",
       "      <td>0.148264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ea_index</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>element</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>errors_leading_to_goal</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>errors_leading_to_goal_attempt</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fixture</th>\n",
       "      <td>0.070795</td>\n",
       "      <td>-0.015925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fouls</th>\n",
       "      <td>-0.062343</td>\n",
       "      <td>0.116675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goals_conceded</th>\n",
       "      <td>0.012400</td>\n",
       "      <td>0.200479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goals_scored</th>\n",
       "      <td>0.924967</td>\n",
       "      <td>0.060726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ict_index</th>\n",
       "      <td>0.842902</td>\n",
       "      <td>0.307052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>0.066350</td>\n",
       "      <td>-0.019546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>influence</th>\n",
       "      <td>0.956420</td>\n",
       "      <td>0.075716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key_passes</th>\n",
       "      <td>0.708261</td>\n",
       "      <td>0.184605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaned_in</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaned_out</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minutes</th>\n",
       "      <td>0.470715</td>\n",
       "      <td>0.338733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offside</th>\n",
       "      <td>0.076913</td>\n",
       "      <td>0.207705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_play_crosses</th>\n",
       "      <td>0.248955</td>\n",
       "      <td>-0.029876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opponent_team</th>\n",
       "      <td>0.255368</td>\n",
       "      <td>0.090719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>own_goals</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>penalties_conceded</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>penalties_missed</th>\n",
       "      <td>-0.180249</td>\n",
       "      <td>-0.101219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>penalties_saved</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recoveries</th>\n",
       "      <td>0.187249</td>\n",
       "      <td>0.062176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>red_cards</th>\n",
       "      <td>-0.202929</td>\n",
       "      <td>0.247163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>round</th>\n",
       "      <td>0.060052</td>\n",
       "      <td>-0.022335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saves</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>selected</th>\n",
       "      <td>0.142364</td>\n",
       "      <td>0.429629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tackled</th>\n",
       "      <td>0.260715</td>\n",
       "      <td>0.085421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tackles</th>\n",
       "      <td>0.252450</td>\n",
       "      <td>0.028591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target_missed</th>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.343988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team_a_score</th>\n",
       "      <td>0.525675</td>\n",
       "      <td>-0.081962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team_h_score</th>\n",
       "      <td>-0.217074</td>\n",
       "      <td>0.068111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threat</th>\n",
       "      <td>0.611039</td>\n",
       "      <td>0.459774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_points</th>\n",
       "      <td>0.979856</td>\n",
       "      <td>0.022470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transfers_balance</th>\n",
       "      <td>0.222090</td>\n",
       "      <td>0.348846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transfers_in</th>\n",
       "      <td>0.141485</td>\n",
       "      <td>0.314602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transfers_out</th>\n",
       "      <td>-0.196724</td>\n",
       "      <td>-0.258900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value</th>\n",
       "      <td>-0.052904</td>\n",
       "      <td>0.229498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>was_home</th>\n",
       "      <td>-0.379993</td>\n",
       "      <td>0.084495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>winning_goals</th>\n",
       "      <td>0.671507</td>\n",
       "      <td>-0.139282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yellow_cards</th>\n",
       "      <td>-0.017226</td>\n",
       "      <td>0.044925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>future_points</th>\n",
       "      <td>-0.013018</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      bps  future_points\n",
       "assists                          0.500451      -0.194994\n",
       "attempted_passes                 0.586816       0.170655\n",
       "big_chances_created              0.333012      -0.004426\n",
       "big_chances_missed               0.048586       0.197941\n",
       "bonus                            0.909670      -0.015912\n",
       "bps                              1.000000      -0.013018\n",
       "clean_sheets                     0.282780       0.242436\n",
       "clearances_blocks_interceptions  0.188060       0.089263\n",
       "completed_passes                 0.614451       0.130888\n",
       "creativity                       0.728404       0.156208\n",
       "dribbles                         0.241634       0.148264\n",
       "ea_index                              NaN            NaN\n",
       "element                               NaN            NaN\n",
       "errors_leading_to_goal                NaN            NaN\n",
       "errors_leading_to_goal_attempt        NaN            NaN\n",
       "fixture                          0.070795      -0.015925\n",
       "fouls                           -0.062343       0.116675\n",
       "goals_conceded                   0.012400       0.200479\n",
       "goals_scored                     0.924967       0.060726\n",
       "ict_index                        0.842902       0.307052\n",
       "id                               0.066350      -0.019546\n",
       "influence                        0.956420       0.075716\n",
       "key_passes                       0.708261       0.184605\n",
       "loaned_in                             NaN            NaN\n",
       "loaned_out                            NaN            NaN\n",
       "minutes                          0.470715       0.338733\n",
       "offside                          0.076913       0.207705\n",
       "open_play_crosses                0.248955      -0.029876\n",
       "opponent_team                    0.255368       0.090719\n",
       "own_goals                             NaN            NaN\n",
       "penalties_conceded                    NaN            NaN\n",
       "penalties_missed                -0.180249      -0.101219\n",
       "penalties_saved                       NaN            NaN\n",
       "recoveries                       0.187249       0.062176\n",
       "red_cards                       -0.202929       0.247163\n",
       "round                            0.060052      -0.022335\n",
       "saves                                 NaN            NaN\n",
       "selected                         0.142364       0.429629\n",
       "tackled                          0.260715       0.085421\n",
       "tackles                          0.252450       0.028591\n",
       "target_missed                    0.095238       0.343988\n",
       "team_a_score                     0.525675      -0.081962\n",
       "team_h_score                    -0.217074       0.068111\n",
       "threat                           0.611039       0.459774\n",
       "total_points                     0.979856       0.022470\n",
       "transfers_balance                0.222090       0.348846\n",
       "transfers_in                     0.141485       0.314602\n",
       "transfers_out                   -0.196724      -0.258900\n",
       "value                           -0.052904       0.229498\n",
       "was_home                        -0.379993       0.084495\n",
       "winning_goals                    0.671507      -0.139282\n",
       "yellow_cards                    -0.017226       0.044925\n",
       "future_points                   -0.013018       1.000000"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat[\"future_points\"] = dat['bps'].shift(+1)\n",
    "dat.corr()[[\"bps\",\"future_points\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data set being used is large, and given that players in different positions will likely have different dependancies on different variables (for example, Sergio_Agüero is a forward so his bps is potentially more dependent on the variable 'creativity' and less dependent on 'clean_sheets' than a defender would be) we will initially use only the most general variables that have the highest correlation with bps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assists</th>\n",
       "      <th>attempted_passes</th>\n",
       "      <th>big_chances_missed</th>\n",
       "      <th>clean_sheets</th>\n",
       "      <th>completed_passes</th>\n",
       "      <th>creativity</th>\n",
       "      <th>dribbles</th>\n",
       "      <th>goals_conceded</th>\n",
       "      <th>goals_scored</th>\n",
       "      <th>ict_index</th>\n",
       "      <th>key_passes</th>\n",
       "      <th>transfers_in</th>\n",
       "      <th>transfers_out</th>\n",
       "      <th>value</th>\n",
       "      <th>bps</th>\n",
       "      <th>total_points</th>\n",
       "      <th>future_points</th>\n",
       "      <th>round</th>\n",
       "      <th>minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>29.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>33</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>13.3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>16.7</td>\n",
       "      <td>1</td>\n",
       "      <td>75648</td>\n",
       "      <td>12138</td>\n",
       "      <td>130</td>\n",
       "      <td>57</td>\n",
       "      <td>13</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>17.5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>1</td>\n",
       "      <td>213510</td>\n",
       "      <td>8885</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>57.0</td>\n",
       "      <td>3</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>32042</td>\n",
       "      <td>984971</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11435</td>\n",
       "      <td>167808</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   assists  attempted_passes  big_chances_missed  clean_sheets  \\\n",
       "0        0                33                   0             0   \n",
       "1        0                21                   0             0   \n",
       "2        0                27                   0             0   \n",
       "3        0                 0                   0             0   \n",
       "4        0                 0                   0             0   \n",
       "\n",
       "   completed_passes  creativity  dribbles  goals_conceded  goals_scored  \\\n",
       "0                26        29.6         1               1             1   \n",
       "1                17        13.3         2               1             2   \n",
       "2                21        17.5         4               1             0   \n",
       "3                 0         0.0         0               0             0   \n",
       "4                 0         0.0         0               0             0   \n",
       "\n",
       "   ict_index  key_passes  transfers_in  transfers_out  value  bps  \\\n",
       "0       14.3           2             0              0    130   33   \n",
       "1       16.7           1         75648          12138    130   57   \n",
       "2        5.2           1        213510           8885    131    6   \n",
       "3        0.0           0         32042         984971    130    0   \n",
       "4        0.0           0         11435         167808    130    0   \n",
       "\n",
       "   total_points  future_points  round  minutes  \n",
       "0             9            NaN      1       90  \n",
       "1            13           33.0      2       82  \n",
       "2             2           57.0      3       87  \n",
       "3             0            6.0      4        0  \n",
       "4             0            0.0      5        0  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables = [\"assists\", \"attempted_passes\", \"big_chances_missed\", \"clean_sheets\", \"completed_passes\",\n",
    "             \"creativity\", \"dribbles\", \"goals_conceded\", \"goals_scored\", \"ict_index\", \"key_passes\",\n",
    "            \"transfers_in\", \"transfers_out\", \"value\", \"bps\", \"total_points\", \"future_points\", \"round\", \"minutes\"]\n",
    "dat = dat[variables]\n",
    "dat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A general function is now required to loop through all the files and select the required columns as shown above. Whilst most files are 38 data entries long, there are some anomolies in length which need to be accounted for, which is done below. Other anomolies, such as missing data, are accounted for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Select_Columns():\n",
    "    new_directory = f\"filtered_data_{datetime.date.today()}\"\n",
    "    os.mkdir(f\"{new_directory}\")\n",
    "    rounds_array = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n",
    "                    21, 22, 23, 24,25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]\n",
    "    \n",
    "    # Fix incorrect indexing in data:\n",
    "    years = [[16, 17], [17, 18], [18, 19]]\n",
    "    for year in years:\n",
    "        player_list = pd.read_csv(f'raw_data/20{year[0]}-{year[1]}/player_idlist.csv')\n",
    "        for i in range(len(player_list)):\n",
    "            try:\n",
    "                player = pd.read_csv(f'raw_data/20{year[0]}-{year[1]}/players/{player_list.iloc[i][0]}_{player_list.iloc[i][1]}/gw.csv')\n",
    "                if len(player[\"round\"]) == 38:\n",
    "                    if player[\"round\"].iloc[-1] != 38:\n",
    "                        player[\"round\"].iloc[-1] = 38\n",
    "                difference_length = 38 - len(player[\"round\"])\n",
    "                if len(player[\"round\"]) == 38:\n",
    "                    player[\"round\"] = rounds_array\n",
    "                else:\n",
    "                    player[\"round\"] = rounds_array[difference_length:]\n",
    "                player[\"future_points\"] = player['bps'].shift(+1)\n",
    "                player = player[variables]\n",
    "                with open(f\"{new_directory}/{player_list.iloc[i][0]}_{player_list.iloc[i][1]}_{year[0]}.csv\", 'w') as file:\n",
    "                    player.to_csv(file, header=True, mode='w',index=False)\n",
    "                        \n",
    "            except:\n",
    "                player = pd.read_csv(f'raw_data/20{year[0]}-{year[1]}/players/{player_list.iloc[i][0]}_{player_list.iloc[i][1]}_{player_list.iloc[i][2]}/gw.csv')\n",
    "                if len(player[\"round\"]) == 38:\n",
    "                    if player[\"round\"].iloc[-1] != 38:\n",
    "                        player[\"round\"].iloc[-1] = 38\n",
    "                difference_length = 38 - len(player[\"round\"])\n",
    "                if len(player[\"round\"]) == 38:\n",
    "                    player[\"round\"] = rounds_array\n",
    "                else:\n",
    "                    player[\"round\"] = rounds_array[difference_length:]\n",
    "                player[\"future_points\"] = player['bps'].shift(+1)\n",
    "                player = player[variables]\n",
    "                with open(f\"{new_directory}/{player_list.iloc[i][0]}_{player_list.iloc[i][1]}_{year[0]}.csv\", 'w') as file:\n",
    "                    player.to_csv(file, header=True, mode='w',index=False)\n",
    "                        \n",
    "    return new_directory\n",
    "\n",
    "working_dir = Select_Columns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the files many not be of length 38 because the player they correspond too didn't play for a club in the premier league for the whole season. In this case, the rounds are re-labelled, to provide some consistency in how the data is formatted, which is necessary as later the rounds will be used as an index. N.b. the fact that the round indices may not be correctly labelled (as some players may play for the first half of the season and others the second etc, and this detail is lost in the above function's relabelling) is not relevant, as the network will be trained to analyse short-term patterns, and thus the time of season is not a factor. However, this is an improvement that could be investigated in future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, normalize and then structure the data in preparation for passing onto the LTSM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalise(passed_directory):\n",
    "    \"\"\" Add new column, 'Performance_direction,' to label whether a player performed better\n",
    "    or worse next week relative to the current week:\"\"\"\n",
    "    \n",
    "    for filename in os.listdir(passed_directory):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            df = pd.read_csv(f\"{passed_directory}/{filename}\")\n",
    "            df[\"performance_direction\"] = list(map(classify, df[\"future_points\"], df[\"total_points\"]))\n",
    "            with open(f\"{passed_directory}/{filename}\", 'w') as file:\n",
    "                df.to_csv(file, header=True, mode='w',index=False)\n",
    "    \n",
    "    \"\"\" Create a new dict to hold the maxiumum values for each variable, which can then\n",
    "    be used to normalise the data. The column 'round' is dropped as it is not a variable,\n",
    "    and 'performance_direction' is added.\"\"\"\n",
    "    \n",
    "    max_values= np.zeros(19)\n",
    "    variables.remove(\"round\")\n",
    "    variables.append(\"performance_direction\")\n",
    "    variables_max_values = dict(zip(variables, max_values))\n",
    "    \"\"\" loop through all files to determine max values\"\"\"\n",
    "    for filename in os.listdir(passed_directory):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            df = pd.read_csv(f\"{passed_directory}/{filename}\")\n",
    "            if len(df.index) > 1:\n",
    "                for var, value in variables_max_values.items():\n",
    "                    if df.at[df[var].idxmax(axis=1), var] > value:\n",
    "                        variables_max_values[var] = df.at[df[var].idxmax(axis=1), var]\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "    \"\"\" loop through a second time to normalise\"\"\"\n",
    "    os.mkdir(f\"Normalised_{passed_directory}\")\n",
    "    for filename in os.listdir(passed_directory):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            df = pd.read_csv(f\"{passed_directory}/{filename}\")\n",
    "            for var, value in variables_max_values.items():\n",
    "                df[var]= df[var].div(value)\n",
    "    \n",
    "        \"\"\" save file for later if there are more than 10 non-zero entries\"\"\"\n",
    "        if df[\"minutes\"][df[\"minutes\"] > 0].count() > 10:\n",
    "            with open(f\"Normalised_{passed_directory}/{filename}\", 'w') as file:\n",
    "                df.to_csv(file, header=True, mode='w', index=False)\n",
    "    new_directory = f\"Normalised_{passed_directory}\"\n",
    "    return variables_max_values, new_directory\n",
    "    \n",
    "normlisation_factors, working_dir = Normalise(working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import random\n",
    "\n",
    "def Sequence_data(passed_directory, length):\n",
    "    j=0\n",
    "    SEQ_LEN = length\n",
    "    sequential_data = []  # this is a list that will CONTAIN the sequences\n",
    "    for filename in os.listdir(f\"{passed_directory}\"):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            df = pd.read_csv(f\"{passed_directory}/{filename}\", index_col=\"round\")\n",
    "            input_df = df[[\"transfers_in\", \"transfers_out\",'bps', 'ict_index', 'minutes', 'performance_direction']]  # performance predictior network from 'bps', 'ict_index', 'minutes'\n",
    "            prev_days = deque(maxlen=SEQ_LEN)  \n",
    "            for i in input_df.values: \n",
    "                prev_days.append([n for n in i[:-1]])  \n",
    "                if len(prev_days) == SEQ_LEN:  \n",
    "                    sequential_data.append([np.array(prev_days), i[-1]])  \n",
    "    random.shuffle(sequential_data)\n",
    "    #print(np.shape(sequential_data))\n",
    "    #normal_data = min_max_scaler.fit_transform(np.array(sequential_data))\n",
    "    return sequential_data\n",
    "\n",
    "Length = 3\n",
    "one= Sequence_data(working_dir, Length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "Y = []\n",
    "for features, result in one:\n",
    "    x.append(features)\n",
    "    Y.append(result)\n",
    "x = np.array(x, dtype=\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40305, 3, 5)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36275 samples, validate on 4031 samples\n",
      "Epoch 1/20\n",
      "36275/36275 [==============================] - 32s 895us/sample - loss: 0.2872 - accuracy: 0.8895 - val_loss: 0.1128 - val_accuracy: 0.9499\n",
      "Epoch 2/20\n",
      "36275/36275 [==============================] - 24s 662us/sample - loss: 0.1179 - accuracy: 0.9572 - val_loss: 0.1147 - val_accuracy: 0.9583\n",
      "Epoch 3/20\n",
      "36275/36275 [==============================] - 27s 755us/sample - loss: 0.0957 - accuracy: 0.9665 - val_loss: 0.0892 - val_accuracy: 0.9677\n",
      "Epoch 4/20\n",
      "36275/36275 [==============================] - 26s 710us/sample - loss: 0.0885 - accuracy: 0.9681 - val_loss: 0.0715 - val_accuracy: 0.9742\n",
      "Epoch 5/20\n",
      "36275/36275 [==============================] - 25s 703us/sample - loss: 0.0830 - accuracy: 0.9706 - val_loss: 0.0712 - val_accuracy: 0.9747\n",
      "Epoch 6/20\n",
      "36275/36275 [==============================] - 25s 700us/sample - loss: 0.0789 - accuracy: 0.9723 - val_loss: 0.0683 - val_accuracy: 0.9747\n",
      "Epoch 7/20\n",
      "36275/36275 [==============================] - 25s 701us/sample - loss: 0.0727 - accuracy: 0.9741 - val_loss: 0.0716 - val_accuracy: 0.9727\n",
      "Epoch 8/20\n",
      "36275/36275 [==============================] - 26s 718us/sample - loss: 0.0745 - accuracy: 0.9734 - val_loss: 0.0798 - val_accuracy: 0.9685\n",
      "Epoch 9/20\n",
      "36275/36275 [==============================] - 26s 704us/sample - loss: 0.0708 - accuracy: 0.9757 - val_loss: 0.0614 - val_accuracy: 0.9759\n",
      "Epoch 10/20\n",
      "36275/36275 [==============================] - 28s 763us/sample - loss: 0.0703 - accuracy: 0.9750 - val_loss: 0.0737 - val_accuracy: 0.9717\n",
      "Epoch 11/20\n",
      "36275/36275 [==============================] - 29s 794us/sample - loss: 0.0670 - accuracy: 0.9755 - val_loss: 0.0697 - val_accuracy: 0.9759\n",
      "Epoch 12/20\n",
      "36275/36275 [==============================] - 29s 786us/sample - loss: 0.0677 - accuracy: 0.9763 - val_loss: 0.0652 - val_accuracy: 0.9732\n",
      "Epoch 13/20\n",
      "36275/36275 [==============================] - 25s 700us/sample - loss: 0.0650 - accuracy: 0.9773 - val_loss: 0.0600 - val_accuracy: 0.9774\n",
      "Epoch 14/20\n",
      "36275/36275 [==============================] - 25s 689us/sample - loss: 0.0635 - accuracy: 0.9786 - val_loss: 0.0614 - val_accuracy: 0.9769\n",
      "Epoch 15/20\n",
      "36275/36275 [==============================] - 26s 721us/sample - loss: 0.0635 - accuracy: 0.9782 - val_loss: 0.0590 - val_accuracy: 0.9779\n",
      "Epoch 16/20\n",
      "36275/36275 [==============================] - 26s 716us/sample - loss: 0.0631 - accuracy: 0.9782 - val_loss: 0.0574 - val_accuracy: 0.9777\n",
      "Epoch 17/20\n",
      "36275/36275 [==============================] - 25s 700us/sample - loss: 0.0620 - accuracy: 0.9784 - val_loss: 0.0747 - val_accuracy: 0.9695\n",
      "Epoch 18/20\n",
      "36275/36275 [==============================] - 26s 710us/sample - loss: 0.0616 - accuracy: 0.9778 - val_loss: 0.0633 - val_accuracy: 0.9752\n",
      "Epoch 19/20\n",
      "36275/36275 [==============================] - 25s 701us/sample - loss: 0.0611 - accuracy: 0.9789 - val_loss: 0.0668 - val_accuracy: 0.9749\n",
      "Epoch 20/20\n",
      "36275/36275 [==============================] - 27s 753us/sample - loss: 0.0602 - accuracy: 0.9788 - val_loss: 0.0612 - val_accuracy: 0.9764\n",
      "\n",
      "history dict: {'loss': [0.2872269661006724, 0.11790631096163119, 0.09565196998935992, 0.08845769866202143, 0.08298545957330504, 0.07887787106358989, 0.072709755674364, 0.07453491659800321, 0.07080402642930071, 0.07029391212413263, 0.0670176158662626, 0.0676957179657052, 0.06502105751976649, 0.06353162377821134, 0.06347888470425185, 0.06309265810998861, 0.06198033247759205, 0.061591503663228596, 0.06114299285892451, 0.06017098011681329], 'accuracy': [0.88945556, 0.9572157, 0.96645075, 0.9681323, 0.9705582, 0.9722674, 0.9740868, 0.9733977, 0.9756582, 0.97499657, 0.9755203, 0.97626466, 0.9773122, 0.97863543, 0.9782219, 0.97816676, 0.9783873, 0.97783595, 0.9789111, 0.97877324], 'val_loss': [0.11282417357441096, 0.11470830587924813, 0.08919945683240654, 0.07147581267688831, 0.07123787375178564, 0.06834922597104283, 0.0715828087043153, 0.07984424846838763, 0.06136052323682259, 0.07371250696108762, 0.06967068963996739, 0.06521365340615186, 0.05998572170885968, 0.061443693605945884, 0.05895870638661469, 0.05735623677654173, 0.07470267512970721, 0.06334569525870991, 0.0668334790051013, 0.06120665234272606], 'val_accuracy': [0.94988835, 0.958323, 0.96774995, 0.97419995, 0.9746961, 0.9746961, 0.9727115, 0.9684942, 0.9759365, 0.9717192, 0.9759365, 0.97320765, 0.977425, 0.97692883, 0.9779211, 0.97767305, 0.9694865, 0.97519225, 0.9749442, 0.9764326]}\n",
      "Test loss: 0.06120665234272606\n",
      "Test accuracy: 0.9764326\n"
     ]
    },
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-2839e67ad9aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLTSM_SHAPE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLTSM_SHAPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-122-2839e67ad9aa>\u001b[0m in \u001b[0;36mNetwork\u001b[0;34m(IN, OUT, TIME_PERIOD, EPOCHS, BATCH_SIZE, LTSM_SHAPE)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# Save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"models\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"models/{NAME}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'models'"
     ]
    }
   ],
   "source": [
    "def Network(IN, OUT, TIME_PERIOD, EPOCHS, BATCH_SIZE, LTSM_SHAPE):\n",
    " \n",
    "    length = len(OUT)\n",
    "    train_x = IN[:int(0.9 * length)]\n",
    "    validation_x = IN[int(0.9 * length):]\n",
    "    train_y = OUT[:int(0.9 * length)]\n",
    "    validation_y = OUT[int(0.9 * length):]\n",
    "\n",
    "    # Define Network & callback:\n",
    "    NAME = f\"pb_{TIME_PERIOD}_{EPOCHS}_{BATCH_SIZE}_{LTSM_SHAPE}_{time.time()}\"\n",
    "    ternsorboard = TensorBoard(log_dir=f\"logs/{NAME}\")\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(LTSM_SHAPE, input_shape=(train_x.shape[1:]), return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization())  # normalizes activation outputs, same reason you want to normalize your input data.\n",
    "\n",
    "    model.add(LSTM(LTSM_SHAPE, return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(LSTM(LTSM_SHAPE))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    \n",
    "    train_y = np.asarray(train_y)\n",
    "    validation_y = np.asarray(validation_y)\n",
    "    history = model.fit(train_x, train_y, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(validation_x, validation_y), callbacks=[ternsorboard])\n",
    "    print('\\nhistory dict:', history.history)\n",
    "\n",
    "    # Score model\n",
    "    score = model.evaluate(validation_x, validation_y, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    # Save model\n",
    "    model.save(f\"models/{NAME}\")\n",
    "\n",
    "EPOCHS, BATCH_SIZE, LTSM_SHAPE = 15, 32, 128\n",
    "\n",
    "Network(x, Y, Length, EPOCHS, BATCH_SIZE, LTSM_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "https://fantasy.premierleague.com/api/my-team/2634476/ -> specifc fantasy team's players\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def Update_files():\n",
    "    url = \"https://fantasy.premierleague.com/api/bootstrap-static/\"\n",
    "    r = requests.get(url)\n",
    "    data = json.loads(r.text)           # Convert data to python dict and then retrive data with the dict:\n",
    "\n",
    "    gameweeks = data['events']          # 'gameweeks' data contains average fantasy team score, the dream team score, and the most select, most transfered in, most captian\n",
    "    # vice-captained and highest sccoring players, with the players being reference using the 'id' tag.\n",
    "    teams = data['teams']\n",
    "    players = data['elements']\n",
    "    for gameweek in gameweeks:\n",
    "        del gameweek['chip_plays']       # Don't need this data and it is problematic to format\n",
    "\n",
    "    for event in gameweeks:              # Get current week.\n",
    "        if event['finished'] == True:\n",
    "            current_gameweek = event['id']\n",
    "        else:\n",
    "            if event[\"finished\"] == False:\n",
    "                break\n",
    "\n",
    "    for player in players:\n",
    "        del (player[\"chance_of_playing_next_round\"],\n",
    "             player[\"chance_of_playing_this_round\"],\n",
    "             player[\"cost_change_event\"],\n",
    "             player[\"cost_change_event_fall\"],\n",
    "             player[\"cost_change_start\"],\n",
    "             player[\"cost_change_start_fall\"],\n",
    "             player[\"value_form\"],\n",
    "             player[\"value_season\"],\n",
    "             player[\"web_name\"],\n",
    "             player[\"transfers_out_event\"],\n",
    "             player[\"transfers_in_event\"],\n",
    "             player[\"status\"],\n",
    "             player[\"squad_number\"],\n",
    "             player[\"special\"],\n",
    "             player[\"photo\"],\n",
    "             player[\"news_added\"],\n",
    "             player[\"news\"],\n",
    "             player[\"ep_this\"],\n",
    "             player[\"ep_next\"])\n",
    "        player[\"Gameweek\"] = current_gameweek\n",
    "\n",
    "    # Save this week's data as a csv and the original json formated data to txt.\n",
    "    player_df = pd.DataFrame(data=players)\n",
    "    gameweeks_df = pd.DataFrame(data=gameweeks)\n",
    "    gameweeks_df.to_csv(\"Gameweeks/Overall_FF_stats.csv\", header=True, mode='w', index=False)\n",
    "    player_df.to_csv(f'Gameweeks/GW{current_gameweek}_player_data.csv', header=True, mode='w', index=False)\n",
    "    pickle.dump(r, open(f\"Gameweeks/GW{current_gameweek}_player_data.txt\", 'wb'))\n",
    "    # Open with p = pickle.load(open(f\"Gameweeks/GW{cuurent_gameweek}_test.txt\", 'rb')) & data = json.loads(p.text)\n",
    "    # Append player data to player files:\n",
    "    for index, player in player_df.iterrows():\n",
    "        if os.path.isfile(f'NEW_DATA_adjusted/{player[\"first_name\"]}_{player[\"second_name\"]}_{player[\"id\"]}.csv') == True:\n",
    "            total_data = pd.read_csv(f'NEW_DATA_adjusted/{player[\"first_name\"]}_{player[\"second_name\"]}_{player[\"id\"]}.csv')\n",
    "            if player[\"Gameweek\"] > total_data[\"Gameweek\"].iloc[-1]:\n",
    "                result = total_data.append(player)\n",
    "                result.to_csv(f'NEW_DATA_adjusted/{player[\"first_name\"]}_{player[\"second_name\"]}_{player[\"id\"]}.csv', header=True, mode='w', index=False)\n",
    "        else:\n",
    "            save_data = pd.DataFrame([player])\n",
    "            save_data.to_csv(f'NEW_DATA_adjusted/{player[\"first_name\"]}_{player[\"second_name\"]}_{player[\"id\"]}.csv', header=True, mode='w', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
